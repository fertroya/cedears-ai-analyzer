# Gu√≠a de Configuraci√≥n de API Keys Gratuitas

Este proyecto soporta m√∫ltiples proveedores de IA, incluyendo opciones **100% gratuitas**.

## üÜì Opci√≥n 1: Google Gemini (RECOMENDADO - Gratis)

### Ventajas
- ‚úÖ Completamente gratis
- ‚úÖ No requiere tarjeta de cr√©dito
- ‚úÖ 60 requests por minuto
- ‚úÖ F√°cil de configurar
- ‚úÖ Buena calidad de an√°lisis

### C√≥mo obtener tu API key

1. Ve a [Google AI Studio](https://aistudio.google.com/)
2. Inicia sesi√≥n con tu cuenta de Google
3. Haz clic en "Get API key" o "Create API key"
4. Copia la API key generada
5. Agrega a tu archivo `.env`:
   ```bash
   GEMINI_API_KEY=tu_api_key_aqui
   ```
6. En `config/config.yaml` aseg√∫rate de tener:
   ```yaml
   ai:
     api_provider: "gemini"
     model: "gemini-1.5-flash"  # Modelo gratuito
   ```

### Modelos disponibles
- `gemini-1.5-flash` - Gratis, r√°pido, recomendado
- `gemini-2.5-flash` - Gratis, mejor calidad

---

## üÜì Opci√≥n 2: Ollama (Gratis - Local)

### Ventajas
- ‚úÖ 100% gratis y sin l√≠mites
- ‚úÖ Privacidad total (corre localmente)
- ‚úÖ Sin necesidad de internet despu√©s de instalar
- ‚úÖ M√∫ltiples modelos disponibles

### Desventajas
- ‚ö†Ô∏è Requiere instalaci√≥n local
- ‚ö†Ô∏è Necesita recursos de tu computadora
- ‚ö†Ô∏è Primera descarga de modelos puede ser grande

### Instalaci√≥n

#### macOS
```bash
brew install ollama
```

#### Linux
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

#### Windows
Descarga desde [ollama.ai](https://ollama.ai/)

### Configuraci√≥n

1. Inicia Ollama:
   ```bash
   ollama serve
   ```

2. Descarga un modelo (opciones recomendadas):
   ```bash
   ollama pull llama3        # Modelo general (4.7GB)
   ollama pull mistral        # Alternativa m√°s peque√±a (4.1GB)
   ollama pull codellama      # Mejor para c√≥digo/an√°lisis t√©cnico
   ```

3. En `config/config.yaml`:
   ```yaml
   ai:
     api_provider: "ollama"
     model: "llama3"  # o "mistral", "codellama"
     ollama_base_url: "http://localhost:11434"
   ```

4. No necesitas API key en `.env` para Ollama

### Verificar que funciona
```bash
curl http://localhost:11434/api/generate -d '{
  "model": "llama3",
  "prompt": "Hola"
}'
```

---

## üÜì Opci√≥n 3: Hugging Face (Gratis con l√≠mites)

### Ventajas
- ‚úÖ Gratis con tier gratuito
- ‚úÖ Miles de modelos disponibles
- ‚úÖ Sin tarjeta de cr√©dito inicialmente

### Desventajas
- ‚ö†Ô∏è L√≠mites de rate en tier gratuito
- ‚ö†Ô∏è Puede requerir tarjeta para algunos modelos

### C√≥mo obtener tu token

1. Ve a [Hugging Face](https://huggingface.co/)
2. Crea una cuenta o inicia sesi√≥n
3. Ve a [Settings > Access Tokens](https://huggingface.co/settings/tokens)
4. Crea un nuevo token con permisos de lectura
5. Agrega a tu `.env`:
   ```bash
   HUGGINGFACE_API_KEY=tu_token_aqui
   ```
6. En `config/config.yaml`:
   ```yaml
   ai:
     api_provider: "huggingface"
     model: "meta-llama/Llama-3-8b"  # Ejemplo
   ```

---

## üí∞ Opci√≥n 4: OpenAI (Pago)

Si prefieres usar OpenAI (GPT-4 o GPT-3.5):

1. Ve a [platform.openai.com](https://platform.openai.com/)
2. Crea una cuenta
3. Ve a API Keys y crea una nueva
4. Agrega a tu `.env`:
   ```bash
   OPENAI_API_KEY=sk-tu_api_key_aqui
   ```
5. En `config/config.yaml`:
   ```yaml
   ai:
     api_provider: "openai"
     model: "gpt-3.5-turbo"  # M√°s econ√≥mico que gpt-4
   ```

---

## Comparaci√≥n R√°pida

| Proveedor | Costo | Calidad | Facilidad | Privacidad |
|-----------|-------|---------|-----------|------------|
| **Gemini** | üÜì Gratis | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Ollama** | üÜì Gratis | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Hugging Face** | üÜì Gratis* | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **OpenAI** | üí∞ Pago | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |

*Con l√≠mites de rate

## Recomendaci√≥n

Para empezar r√°pidamente: **Google Gemini** (Opci√≥n 1)
- Es gratis
- F√°cil de configurar
- Buena calidad
- No requiere instalaci√≥n

Para m√°xima privacidad: **Ollama** (Opci√≥n 2)
- Corre completamente local
- Sin l√≠mites
- Requiere m√°s setup inicial
